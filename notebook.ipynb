{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making clusters out of the embedded data. These clusters represent the data of each individual for categorization purposes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "# extract_frames: function that takes a video file path and extracts frames from the video.\n",
    "# params\n",
    "# video_file_path:   the path to the video file\n",
    "# video_name:        the name of the video file\n",
    "# sample_every:      the number of frames to skip between samples\n",
    "# return:            a list of frames extracted from the video\n",
    "\n",
    "def extract_frames(video_file_path, video_name, sample_every):\n",
    "  print('Start extracting frames')\n",
    "  frame_list = []\n",
    "  video_path = os.path.join(video_file_path, video_name)\n",
    "  cap = cv.VideoCapture(video_path)\n",
    "  if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file.\")\n",
    "    return []\n",
    "  i = 0\n",
    "  captured = 0\n",
    "  while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "      break\n",
    "    if i % sample_every == 0:\n",
    "      frame_rgb = np.ascontiguousarray(cv.cvtColor(frame, cv.COLOR_BGR2RGB))\n",
    "      mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "      frame_list.append(mp_image)\n",
    "      captured += 1\n",
    "    i += 1\n",
    "  cap.release()\n",
    "  cv.destroyAllWindows()\n",
    "  print(f\"Successfully captured {captured} frames\")\n",
    "  return frame_list\n",
    "\n",
    "# save_face_list: function that takes a list of faces and saves them to a folder.\n",
    "# params\n",
    "# face_list_movie:    the list of faces to be saved\n",
    "# faces_folder:       the folder to save the faces\n",
    "# movie:              the name of the movie\n",
    "# extension:          the extension of the saved faces\n",
    "# return:             None\n",
    "\n",
    "def save_face_list(face_list_movie,faces_folder,movie,extension):\n",
    "  saved_faces = 0\n",
    "  for i, face in enumerate(face_list_movie):\n",
    "      if face.shape[0] > 10 and face.shape[1] > 10:\n",
    "          cv.imwrite(faces_folder + movie + '_' + str(saved_faces) + extension, face)\n",
    "          saved_faces += 1\n",
    "  return"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\\\ningw\\\\Desktop\\\\Test.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file.\")\n",
    "else:\n",
    "    print(\"Video file opened successfully!\")\n",
    "cap.release()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from utils import save_face_list, extract_frames\n",
    "from face_extraction import process_image, check_face\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "\n",
    "MOVIE_FOLDER = \"C:\\\\Users\\\\ningw\\\\Desktop\"\n",
    "FRAME_FOLDER = \"C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\"\n",
    "FACES_FOLDER_TRAINING = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\face_folder\\\\'\n",
    "FACES_FOLDER_TEST = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\face_folder_test\\\\'\n",
    "MOVIE_TRAINING_LIST = ['New Kids ABC','New Kids Fussballspiel','New Kids Turbo_ Tankstation']\n",
    "MOVIE_TEST_LIST = ['Test']\n",
    "\n",
    "output_extension= '.png'\n",
    "input_extension = '.mp4'\n",
    "samples_per_second = 10         #FPS rate is assumed 25\n",
    "padding_x = 10\n",
    "padding_y = 10\n",
    "min_confidence = 0.5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "for movie in MOVIE_TRAINING_LIST:\n",
    "  print(movie+input_extension)\n",
    "  frame_list = extract_frames(MOVIE_FOLDER,movie+input_extension,samples_per_second)\n",
    "  face_list_movie = []\n",
    "  for frame in frame_list:\n",
    "    face_list_frame = process_image(frame,padding_x,padding_y,min_confidence)\n",
    "    for face in face_list_frame:\n",
    "      if check_face(face,mtcnn):\n",
    "        face_list_movie.append(face)\n",
    "  print('saving')\n",
    "  save_face_list(face_list_movie,FACES_FOLDER_TRAINING,movie,output_extension)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path  # import Path from pathlib module\n",
    "from embed import embed_face_net\n",
    "\n",
    "\n",
    "FACES_FOLDER_TRAINING = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\face_folder\\\\'\n",
    "OUTPUT_FOLDER_RESULTS = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\results\\\\'\n",
    "RESULTS_NAME = 'second_results.csv'\n",
    "directory = Path(FACES_FOLDER_TRAINING)\n",
    "\n",
    "\n",
    "vector_embedding = dict()\n",
    "for file in directory.iterdir():  \n",
    "  if file.is_file():\n",
    "    file_name = file.name  \n",
    "    print(file_name)\n",
    "    path = FACES_FOLDER_TRAINING + file_name\n",
    "    img = cv2.imread(path)\n",
    "    vector = embed_face_net(img)\n",
    "    vector_np = vector.detach().numpy()\n",
    "    vector_embedding[file.name] = vector_np.flatten()\n",
    "    \n",
    "embedding_df = pd.DataFrame(vector_embedding)\n",
    "print(embedding_df.shape)\n",
    "\n",
    "embedding_df.to_csv(OUTPUT_FOLDER_RESULTS+RESULTS_NAME, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score, pairwise_distances_argmin_min\n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# find_best_number_of_clusters: function that takes a csv file with embeddings and finds the best number of clusters for KMeans clustering.\n",
    "# params\n",
    "# results_csv:       the csv file with the embeddings\n",
    "# min_clusters:      the minimum number of clusters to test\n",
    "# max_clusters:      the maximum number of clusters to test\n",
    "# return:            the best number of clusters based on silhouette score and calinski-harabasz score\n",
    "\n",
    "def find_best_number_of_clusters(results_csv, min_clusters=2, max_clusters=15):\n",
    "    embeddings_df = pd.read_csv(results_csv)\n",
    "    embeddings = embeddings_df.T.values\n",
    "    best_silhouette_score = -1\n",
    "    best_calinski_score = -1\n",
    "    best_n_clusters_silhouette = min_clusters\n",
    "    best_n_clusters_calinski = min_clusters\n",
    "    silhouette_scores = []\n",
    "    calinski_scores = []\n",
    "\n",
    "    if not os.path.exists('Plots'):\n",
    "        os.makedirs('Plots')\n",
    "    if not os.path.exists('KMEANS_OUTPUT'):\n",
    "        os.makedirs('KMEANS_OUTPUT')\n",
    "\n",
    "    for n_clusters in range(min_clusters, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(embeddings)\n",
    "        labels = kmeans.labels_\n",
    "        silhouette_avg = silhouette_score(embeddings, labels)\n",
    "        calinski_avg = calinski_harabasz_score(embeddings, labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        calinski_scores.append(calinski_avg)\n",
    "        if silhouette_avg > best_silhouette_score:\n",
    "            best_silhouette_score = silhouette_avg\n",
    "            best_n_clusters_silhouette = n_clusters\n",
    "\n",
    "        if calinski_avg > best_calinski_score:\n",
    "            best_calinski_score = calinski_avg\n",
    "            best_n_clusters_calinski = n_clusters\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(min_clusters, max_clusters + 1), silhouette_scores, marker='o', label='Silhouette Score')\n",
    "    plt.axvline(x=best_n_clusters_silhouette, color='r', linestyle='--', label=f'Best Clustering ({best_n_clusters_silhouette})')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette score')\n",
    "    plt.legend()\n",
    "    plt.title('Silhouette score vs number of clusters')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(min_clusters, max_clusters + 1), calinski_scores, marker='o', label='Calinski-Harabasz Score')\n",
    "    plt.axvline(x=best_n_clusters_calinski, color='r', linestyle='--', label=f'Best Clustering ({best_n_clusters_calinski})')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Calinski-Harabasz score')\n",
    "    plt.legend()\n",
    "    plt.title('Calinski-Harabasz score vs number of clusters')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Plots/clustering_scores.png')\n",
    "    plt.show()\n",
    "\n",
    "    return best_n_clusters_silhouette, best_n_clusters_calinski\n",
    "\n",
    "\n",
    "# separate_images_by_clusters: function that takes a csv file with embeddings and separates the images into clusters based on KMeans clustering.\n",
    "# params\n",
    "# results_csv:          the csv file with the embeddings\n",
    "# faces_folder:         the folder with the images\n",
    "# output_base_folder:   the folder to save the clustered images\n",
    "# n_clusters:           the number of clusters to use\n",
    "# thresholdperentile:   the percentile to use for the threshold distance\n",
    "# return:               None\n",
    "def separate_images_by_clusters(results_csv, faces_folder, output_base_folder, n_clusters=2, thresholdperentile=95):\n",
    "    embeddings_df = pd.read_csv(results_csv)\n",
    "    embeddings = embeddings_df.T.values\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(embeddings)\n",
    "    joblib.dump(kmeans, os.path.join(output_base_folder, 'kmeans.pkl'))\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    distances = pairwise_distances_argmin_min(embeddings, kmeans.cluster_centers_,metric='euclidean' )[1]\n",
    "    threshold_distance = np.percentile(distances, thresholdperentile)\n",
    "\n",
    "    sns.histplot(distances)\n",
    "    plt.axvline(threshold_distance, color='r', linestyle='--', label=f'95th percentile ({threshold_distance:.2f})')\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.title('Distribution of distances to cluster centers')\n",
    "    plt.savefig('Plots/clusertering_distances.png')\n",
    "    plt.show()\n",
    "\n",
    "    for i, file_name in enumerate(embeddings_df.columns):\n",
    "        src_path = os.path.join(faces_folder, file_name)\n",
    "        if distances[i] > threshold_distance:\n",
    "            dst_path = os.path.join(output_base_folder, 'outliers', file_name)\n",
    "        else:\n",
    "            dst_path = os.path.join(output_base_folder, f'cluster_{labels[i]}', file_name)\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "RESULTS_CSV = 'results\\\\second_results.csv'\n",
    "FACES_FOLDER = 'face_folder\\\\'\n",
    "OUTPUT_BASE_FOLDER = 'KMEANS_OUTPUT'\n",
    "\n",
    "best_clusters_silhouette, best_clusters_calinski = find_best_number_of_clusters(RESULTS_CSV)\n",
    "separate_images_by_clusters(RESULTS_CSV, FACES_FOLDER, OUTPUT_BASE_FOLDER, n_clusters=best_clusters_silhouette, thresholdperentile=95)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for movie in MOVIE_TEST_LIST:\n",
    "  print(movie+input_extension)\n",
    "  frame_list = extract_frames(MOVIE_FOLDER,movie+input_extension,samples_per_second)\n",
    "  face_list_movie = []\n",
    "  for frame in frame_list:\n",
    "    face_list_frame = process_image(frame,padding_x,padding_y,min_confidence)\n",
    "    for face in face_list_frame:\n",
    "      if check_face(face,mtcnn):\n",
    "        face_list_movie.append(face)\n",
    "  print('saving')\n",
    "  save_face_list(face_list_movie,FACES_FOLDER_TEST,movie,output_extension)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "FACES_FOLDER_TEST = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\face_folder_test\\\\'\n",
    "OUTPUT_FOLDER_RESULTS = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\results_test\\\\'\n",
    "RESULTS_NAME = 'test_results.csv'\n",
    "directory = Path(FACES_FOLDER_TEST)\n",
    "\n",
    "\n",
    "vector_embedding = dict()\n",
    "for file in directory.iterdir():  \n",
    "  if file.is_file():\n",
    "    file_name = file.name  \n",
    "    print(file_name)\n",
    "    path = FACES_FOLDER_TEST + file_name\n",
    "    img = cv2.imread(path)\n",
    "    vector = embed_face_net(img)\n",
    "    vector_np = vector.detach().numpy()\n",
    "    vector_embedding[file.name] = vector_np.flatten()\n",
    "    \n",
    "embedding_df = pd.DataFrame(vector_embedding)\n",
    "print(embedding_df.shape)\n",
    "\n",
    "embedding_df.to_csv(OUTPUT_FOLDER_RESULTS+RESULTS_NAME, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define file paths\n",
    "TEST_RESULTS_CSV = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\results_test\\\\test_results.csv'\n",
    "CLUSTER_MODEL_PATH = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\Assignment 3\\\\KTA3\\\\KMEANS_OUTPUT\\\\kmeans.pkl'\n",
    "\n",
    "# Load test embeddings and KMeans model\n",
    "test_embeddings_df = pd.read_csv(TEST_RESULTS_CSV)\n",
    "test_embeddings = test_embeddings_df.T.values\n",
    "kmeans = joblib.load(CLUSTER_MODEL_PATH)\n",
    "\n",
    "# Use predict to match each image to a cluster\n",
    "predicted_clusters = kmeans.predict(test_embeddings)\n",
    "\n",
    "# Create a mapping of images to their predicted clusters\n",
    "image_cluster_results = []\n",
    "for i, cluster in enumerate(predicted_clusters):\n",
    "    image_cluster_results.append({\n",
    "        \"Image\": test_embeddings_df.columns[i],\n",
    "        \"Cluster\": cluster\n",
    "    })\n",
    "    print(f\"Image {test_embeddings_df.columns[i]} belongs to Cluster {cluster}\")\n",
    "\n",
    "# Save image-to-cluster mapping\n",
    "results_df = pd.DataFrame(image_cluster_results)\n",
    "results_output_path = 'image_to_cluster_results.csv'\n",
    "results_df.to_csv(results_output_path, index=False)\n",
    "print(f\"Image-to-cluster mapping saved at {results_output_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 2: Count how often each cluster has appeared (chronologically with missing clusters included)\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Load image-to-cluster mapping\n",
    "image_to_cluster_path = 'image_to_cluster_results.csv'\n",
    "image_cluster_results = pd.read_csv(image_to_cluster_path)\n",
    "\n",
    "# Count the occurrences of each cluster\n",
    "cluster_counts = Counter(image_cluster_results[\"Cluster\"])\n",
    "\n",
    "# Ensure all clusters from 0 to 11 are included, even if their count is 0\n",
    "max_cluster = 11  # Adjust this number based on the maximum number of clusters\n",
    "cluster_counts_complete = {cluster: cluster_counts.get(cluster, 0) for cluster in range(max_cluster + 1)}\n",
    "\n",
    "# Print cluster appearance counts in chronological order\n",
    "print(\"\\nCluster Appearance Counts (Chronological Order):\")\n",
    "for cluster in range(max_cluster + 1):\n",
    "    print(f\"Cluster {cluster}: {cluster_counts_complete[cluster]} appearances\")\n",
    "\n",
    "# Save the counts to a CSV file\n",
    "cluster_counts_df = pd.DataFrame(cluster_counts_complete.items(), columns=[\"Cluster\", \"Count\"])\n",
    "cluster_counts_output_path = 'cluster_appearance_counts.csv'\n",
    "cluster_counts_df.to_csv(cluster_counts_output_path, index=False)\n",
    "print(f\"Cluster appearance counts saved at {cluster_counts_output_path}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing New Kids ABC...\n",
      "Start extracting frames...\n",
      "Error: Cannot open video file.\n",
      "Saving faces...\n",
      "Saved 0 faces to C:\\Users\\ningw\\Desktop\\KTA3\\face_folder\\.\n",
      "Processing New Kids Fussballspiel...\n",
      "Start extracting frames...\n",
      "Error: Cannot open video file.\n",
      "Saving faces...\n",
      "Saved 0 faces to C:\\Users\\ningw\\Desktop\\KTA3\\face_folder\\.\n",
      "Processing New Kids Turbo_Tankstation...\n",
      "Start extracting frames...\n",
      "Error: Cannot open video file.\n",
      "Saving faces...\n",
      "Saved 0 faces to C:\\Users\\ningw\\Desktop\\KTA3\\face_folder\\.\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from pathlib import Path\n",
    "from face_extraction import process_image\n",
    "\n",
    "# Define paths\n",
    "MOVIE_FOLDER = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\KTA3\\\\movies\\\\'\n",
    "FRAME_FOLDER = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\KTA3\\\\output_images\\\\'\n",
    "FACES_FOLDER_TRAINING = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\KTA3\\\\face_folder\\\\'\n",
    "OUTPUT_FOLDER_RESULTS = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\KTA3\\\\results\\\\'\n",
    "RESULTS_NAME = 'first_result.csv'\n",
    "OUTPUT_BASE_FOLDER = 'C:\\\\Users\\\\ningw\\\\Desktop\\\\KTA3\\\\clusters\\\\'\n",
    "\n",
    "# Frame extraction function\n",
    "def extract_frames(video_file_path, video_name, sample_rate):\n",
    "    \"\"\"\n",
    "    Extract frames from a video at a specific sampling rate.\n",
    "\n",
    "    Args:\n",
    "        video_file_path (str): Path to the folder containing the video file.\n",
    "        video_name (str): Name of the video file.\n",
    "        sample_rate (int): Frequency of frames to capture.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of frames as mediapipe Image objects.\n",
    "    \"\"\"\n",
    "    print(\"Start extracting frames...\")\n",
    "    video_path = os.path.join(video_file_path, video_name)\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    frame_list = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video file.\")\n",
    "        return frame_list\n",
    "\n",
    "    frame_idx, captured = 0, 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % sample_rate == 0:\n",
    "            frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "            frame_list.append(mp_image)\n",
    "            captured += 1\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Successfully extracted {captured} frames.\")\n",
    "    return frame_list\n",
    "\n",
    "# Save faces function\n",
    "def save_face_list(face_list, output_folder, movie_name, file_extension=\".png\"):\n",
    "    \"\"\"\n",
    "    Save detected faces to files.\n",
    "\n",
    "    Args:\n",
    "        face_list (list): List of cropped face images.\n",
    "        output_folder (str): Folder to save the images.\n",
    "        movie_name (str): Name of the movie being processed.\n",
    "        file_extension (str): File extension for the saved images.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(\"Saving faces...\")\n",
    "    for idx, face in enumerate(face_list):\n",
    "        file_path = os.path.join(output_folder, f\"{movie_name}_{idx}{file_extension}\")\n",
    "        cv.imwrite(file_path, face)\n",
    "    print(f\"Saved {len(face_list)} faces to {output_folder}.\")\n",
    "\n",
    "# Extract faces function\n",
    "def extract_faces(image, detection_result, padding_x, padding_y):\n",
    "    \"\"\"\n",
    "    Extract faces from an image based on face detection results.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image.\n",
    "        detection_result (mediapipe.tasks.python.vision.Detection): Face detection results.\n",
    "        padding_x (int): Horizontal padding.\n",
    "        padding_y (int): Vertical padding.\n",
    "\n",
    "    Returns:\n",
    "        list: List of cropped face images.\n",
    "    \"\"\"\n",
    "    cropped_faces = []\n",
    "    for detection in detection_result.detections:\n",
    "        bbox = detection.bounding_box\n",
    "        x_start = max(0, bbox.origin_x - padding_x)\n",
    "        y_start = max(0, bbox.origin_y - padding_y)\n",
    "        x_end = min(image.shape[1], bbox.origin_x + bbox.width + padding_x)\n",
    "        y_end = min(image.shape[0], bbox.origin_y + bbox.height + padding_y)\n",
    "        cropped_face = image[y_start:y_end, x_start:x_end]\n",
    "        if cropped_face.size > 0 and cropped_face.shape[0] > 10 and cropped_face.shape[1] > 10:\n",
    "            cropped_faces.append(cv.cvtColor(cropped_face, cv.COLOR_RGB2BGR))\n",
    "    return cropped_faces\n",
    "\n",
    "# Embed face function\n",
    "def embed_face_net(image):\n",
    "    \"\"\"\n",
    "    Generate a facial embedding from an image using a pretrained FaceNet model.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Cropped face image.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Facial embedding vector.\n",
    "    \"\"\"\n",
    "    model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "    img_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img_tensor = transform(img_rgb).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        return model(img_tensor)\n",
    "\n",
    "# Main processing\n",
    "MOVIE_TRAINING_LIST = [\"New Kids ABC\", \"New Kids Fussballspiel\", \"New Kids Turbo_Tankstation\"]\n",
    "RESULTS_CSV = os.path.join(OUTPUT_FOLDER_RESULTS, RESULTS_NAME)\n",
    "output_extension = \".png\"\n",
    "input_extension = \".mp4\"\n",
    "samples_per_second = 25\n",
    "padding_x = 10\n",
    "padding_y = 10\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Ensure directories exist\n",
    "Path(FACES_FOLDER_TRAINING).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for movie in MOVIE_TRAINING_LIST:\n",
    "    print(f\"Processing {movie}...\")\n",
    "    frames = extract_frames(MOVIE_FOLDER, movie + input_extension, samples_per_second)\n",
    "    faces = []\n",
    "    for frame in frames:\n",
    "        detection_result = process_image(frame, padding_x, padding_y, min_confidence)\n",
    "        faces.extend(extract_faces(frame, detection_result, padding_x, padding_y))\n",
    "    save_face_list(faces, FACES_FOLDER_TRAINING, movie, output_extension)\n",
    "\n",
    "print(\"Processing complete!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making clusters out of the embedded data. These clusters represent the data of each individual for categorization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_face_list, extract_frames\n",
    "from face_extraction import process_image, check_face\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import cv2\n",
    "from main_extract_faces import process_movies\n",
    "from main_unsupervised import find_best_number_of_clusters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import os\n",
    "import shutil\n",
    "import plots\n",
    "import augmentation\n",
    "import main_embed\n",
    "import cluster_dataframe\n",
    "import embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video File Handling Code Explanation\n",
    "\n",
    "This code snippet is responsible for loading and verifying the accessibility of a specific video file using OpenCV (`cv2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks your current directory. Using it as a validation that you are in correct directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_FOLDER = \"C:\\\\Users\\\\ningw\\\\Desktop\\\\\"  # Change this path to where you stored your movies (don't forget to add \\\\ at end)\n",
    "\n",
    "# Input and output file extensions for video files and images\n",
    "input_extension = '.mp4'\n",
    "output_extension = '.png'\n",
    "samples_per_second = 10\n",
    "padding_x = 10\n",
    "padding_y = 10\n",
    "min_confidence = 0.5\n",
    "\n",
    "# List of movie names for training and testing\n",
    "MOVIE_TRAINING_LIST = ['New_Kids_ABC', 'New_Kids_Fussballspiel', \n",
    "                       'New_Kids_Turbo_Tankstation', 'New_Kids_Nitro_Peter_lemonade_720']\n",
    "MOVIE_TEST_LIST = ['Test']\n",
    "\n",
    "# Define current directory variable\n",
    "current_directory = os.getcwd()  # Dynamically set to the current working directory\n",
    "\n",
    "# Define paths using the current directory variable\n",
    "FACES_FOLDER_TRAINING = f\"{current_directory}\\\\face_folder\\\\\"\n",
    "FACES_FOLDER_TEST = f\"{current_directory}\\\\face_folder_test\\\\\"\n",
    "\n",
    "OUTPUT_FOLDER_RESULTS_TRAIN = f\"{current_directory}\\\\results\\\\\"\n",
    "RESULTS_NAME_TRAIN = \"results.csv\"\n",
    "RESULTS_CSV_TRAIN = f\"{OUTPUT_FOLDER_RESULTS_TRAIN}\\\\{RESULTS_NAME_TRAIN}\"\n",
    "\n",
    "OUTPUT_FOLDER_RESULTS_TEST = f\"{current_directory}\\\\results_test\\\\\"\n",
    "RESULTS_NAME_TEST = \"test_results.csv\"\n",
    "RESULTS_CSV_TEST = f\"{OUTPUT_FOLDER_RESULTS_TEST}\\\\{RESULTS_NAME_TEST}\"\n",
    "\n",
    "KMEANS_OUTPUT_FOLDER = f\"{current_directory}\\\\KMEANS_OUTPUT\\\\\"\n",
    "CLUSTER_MODEL_PATH = f\"{KMEANS_OUTPUT_FOLDER}\\\\kmeans.pkl\"\n",
    "\n",
    "# List of all directories\n",
    "directories = [FACES_FOLDER_TRAINING, FACES_FOLDER_TEST, \n",
    "               OUTPUT_FOLDER_RESULTS_TRAIN, OUTPUT_FOLDER_RESULTS_TEST, \n",
    "               KMEANS_OUTPUT_FOLDER]\n",
    "\n",
    "# Check if each directory exists, and create it if it doesn't\n",
    "for path in directories:\n",
    "    if not os.path.isdir(path):  # Check if the directory exists\n",
    "        os.makedirs(path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "        print(f\"Checked/Created directory: {path}\")  # Confirm creation of the directory\n",
    "    else:\n",
    "        print(f\"Directory already exists: {path}\")  # Confirm the directory already exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video File Handling Code Explanation\n",
    "\n",
    "This code snippet is responsible for loading and verifying the accessibility of a specific video file using OpenCV (`cv2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV's VideoCapture is initialized with the path to a video file.\n",
    "cap = cv2.VideoCapture(MOVIE_FOLDER + MOVIE_TRAINING_LIST[1] + '.mp4')  # Construct the full file path using MOVIE_FOLDER and the second video name in the list.\n",
    "\n",
    "# Check if the video file has been successfully opened.\n",
    "if not cap.isOpened():  # .isOpened() returns False if the video file cannot be accessed.\n",
    "    print(\"Error: Cannot open video file.\")  # Print an error message if the video file cannot be opened.\n",
    "else:\n",
    "    print(\"Video file opened successfully!\")  # Print a success message if the video file is opened correctly.\n",
    "\n",
    "# Release the resources associated with the VideoCapture object.\n",
    "cap.release()  # It's important to release the VideoCapture object to free resources and avoid memory leaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the `process_movies` Function with Defined Variables\n",
    "\n",
    "The `process_movies` function is designed to process a list of movies, extract faces from their frames, and save the extracted faces to a specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function using the defined variables\n",
    "process_movies(\n",
    "    movie_list=MOVIE_TRAINING_LIST,\n",
    "    movie_folder=MOVIE_FOLDER,\n",
    "    faces_folder=FACES_FOLDER_TRAINING,\n",
    "    input_extension=input_extension,\n",
    "    output_extension=output_extension,\n",
    "    samples_per_second=samples_per_second,\n",
    "    padding_x=padding_x,\n",
    "    padding_y=padding_y,\n",
    "    min_confidence=min_confidence\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the `embed` Function for the training\n",
    "\n",
    "The `embed` function is designed to process training face images stored in a folder, compute their embeddings using a neural network, and save the resulting embeddings to a CSV file in the specified output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_embed.embed(FACES_FOLDER_TRAINING, OUTPUT_FOLDER_RESULTS_TRAIN,RESULTS_NAME_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Optimal Number of Clusters: Calinski-Harabasz vs. Silhouette\n",
    "\n",
    "In our clustering process, we evaluated two different methods to determine the optimal number of clusters: **Silhouette Score** and **Calinski-Harabasz Score**. We opted for the Calinski since it performed better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the find_best_number_of_clusters function to determine the optimal number of clusters \n",
    "# based on silhouette and Calinski-Harabasz scores from the training results.\n",
    "best_clusters_silhouette, best_clusters_calinski = find_best_number_of_clusters(RESULTS_CSV_TRAIN)\n",
    "\n",
    "# We had to choose between Silhouette or Calinski. We opted to go for Calinski score for our cluster choice. \n",
    "# We found that running with 7 clusters leads to too many overlaps with identities\n",
    "cluster_choice = best_clusters_calinski\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing testing data\n",
    "\n",
    "We do the same processing for our testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call for testing movies\n",
    "process_movies(\n",
    "    movie_list=MOVIE_TEST_LIST,\n",
    "    movie_folder=MOVIE_FOLDER,\n",
    "    faces_folder=FACES_FOLDER_TEST,\n",
    "    input_extension=input_extension,\n",
    "    output_extension=output_extension,\n",
    "    samples_per_second=samples_per_second,\n",
    "    padding_x=padding_x,\n",
    "    padding_y=padding_y,\n",
    "    min_confidence=min_confidence\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_embed.embed(FACES_FOLDER_TEST,OUTPUT_FOLDER_RESULTS_TEST,RESULTS_NAME_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Outcomes\n",
    "\n",
    "After successfully processing the embeddings and organizing images based on clusters and outliers, we are now starting to explore the results of our analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training embeddings from the CSV file\n",
    "train_embeddings_df = pd.read_csv(RESULTS_CSV_TRAIN)  # Read embeddings for training faces into a DataFrame.\n",
    "trains_embeddings = train_embeddings_df.T.values  # Transpose the DataFrame and convert it to NumPy array format.\n",
    "\n",
    "# Load testing embeddings from the CSV file\n",
    "test_embeddings_df = pd.read_csv(RESULTS_CSV_TEST)  # Read embeddings for test faces into a DataFrame.\n",
    "test_embeddings = test_embeddings_df.T.values  # Transpose the DataFrame and convert it to NumPy array format.\n",
    "\n",
    "# Perform KMeans clustering on the training embeddings\n",
    "kmeans = KMeans(random_state=0, n_clusters=cluster_choice).fit(trains_embeddings)  # Fit KMeans model using the training embeddings.\n",
    "labels = kmeans.labels_  # Assign cluster labels to the training embeddings.\n",
    "\n",
    "# Calculate distances from each point to its closest cluster center\n",
    "distances_train = pairwise_distances_argmin_min(trains_embeddings, kmeans.cluster_centers_)[1]  # Compute distances from each embedding to its cluster center.\n",
    "\n",
    "# Determine the 85th percentile distance as the threshold for outliers\n",
    "threshold_distance_85 = np.percentile(distances_train, 85)  # Set the threshold based on the 85th percentile of distances.\n",
    "\n",
    "# Plot histogram of distances and the 85th percentile threshold\n",
    "plots.plot_histplot_percentile(distances_train, threshold_distance_85)  # Generate a histogram to visualize distances.\n",
    "\n",
    "# Remove embeddings considered outliers based on the threshold\n",
    "for i, file_name in enumerate(train_embeddings_df.columns):  # Iterate over each column (embedding) in the DataFrame.\n",
    "    if distances_train[i] > threshold_distance_85:  # Check if the distance exceeds the outlier threshold.\n",
    "        train_embeddings_df.drop(file_name, axis='columns', inplace=True)  # Drop the outlier column from the DataFrame.\n",
    "\n",
    "# Recompute embeddings array after removing outliers\n",
    "trains_embeddings = train_embeddings_df.T.values  # Update the embeddings array after removing outliers.\n",
    "\n",
    "# Re-run KMeans clustering with a higher maximum iteration limit\n",
    "kmeans = KMeans(random_state=0, n_clusters=cluster_choice, max_iter=600).fit(trains_embeddings)  # Fit the updated training embeddings to KMeans.\n",
    "labels = kmeans.labels_  # Get updated cluster labels after re-running KMeans.\n",
    "\n",
    "# Organize images into cluster folders and outlier folders\n",
    "for i, file_name in enumerate(train_embeddings_df.columns):  # Iterate through each embedding in the DataFrame.\n",
    "    src_path = os.path.join(FACES_FOLDER_TRAINING, file_name)  # Define the source path of the image.\n",
    "    \n",
    "    # Assign the image to the \"outliers\" folder or its respective cluster folder\n",
    "    if distances_train[i] > threshold_distance_85:  # Check if the image is an outlier.\n",
    "        dst_path = os.path.join(KMEANS_OUTPUT_FOLDER, 'outliers', file_name)  # Set destination to \"outliers\" folder.\n",
    "    else:\n",
    "        dst_path = os.path.join(KMEANS_OUTPUT_FOLDER, f'cluster_{labels[i]}', file_name)  # Set destination to the corresponding cluster folder.\n",
    "\n",
    "    # Ensure the destination directory exists before saving the image\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)  # Create the directory if it does not exist.\n",
    "    shutil.copy(src_path, dst_path)  # Copy the image to the destination path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T19:46:36.535195Z",
     "start_time": "2025-04-10T19:45:53.488939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a dictionary to store DataFrames.\n",
    "df_dict = {}\n",
    "\n",
    "# Define a list of thresholds to evaluate.\n",
    "thresholds = [0.80, 0.85, 0.9, 0.95]\n",
    "\n",
    "# Iterate through each threshold value.\n",
    "for threshold in thresholds:\n",
    "    # Calculate the threshold distance for the current percentile of the training distances.\n",
    "    threshold_distance = np.percentile(distances_train, threshold * 100)  \n",
    "    \n",
    "    # Process test videos to create a DataFrame of clusters using the calculated threshold distance.\n",
    "    clusterdf = cluster_dataframe.process_videos_to_dataframe(\n",
    "        MOVIE_TEST_LIST, MOVIE_FOLDER, kmeans, threshold_distance_85=threshold_distance\n",
    "    )\n",
    "    \n",
    "    # Store the DataFrame in the dictionary with the threshold as the key.\n",
    "    df_dict[f\"df_{threshold}\"] = clusterdf\n",
    "\n",
    "    # Plot the presence of clusters in the sorted DataFrame to visualize their distribution.\n",
    "    plots.plot_cluster_presence(clusterdf.sort_index(ascending=False))\n",
    "\n",
    "# At the end of the loop, you will have separate DataFrame variables like df_0.80, df_0.85, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames for Heatmaps\n",
    "\n",
    "Listed below are the DataFrames generated from the earlier loop. These DataFrames are used to create the heatmaps. For your convenience, we've included them here, allowing you to explore the results if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"df_80\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"df_85\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"df_90\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"df_95\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Image Augmentation to Assess Impact\n",
    "\n",
    "Image augmentation is a technique used to artificially adjust the dataset by applying transformations such as flipping, rotation, noise addition, or distortion. This helps evaluate the robustness of clustering and embedding models when faced with varied and augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply image augmentations to the test face images stored in FACES_FOLDER_TEST.\n",
    "# The augmented images are saved in a designated folder named 'AUGMENTED'.\n",
    "augmentation.process_images_with_augmentations(FACES_FOLDER_TEST, 'AUGMENTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all folders in the 'AUGMENTED' directory\n",
    "for folder_name in os.listdir('AUGMENTED'):  # List all items in the 'AUGMENTED' directory.\n",
    "    folder_path = os.path.join('AUGMENTED', folder_name, '')  # Construct the full path to the current folder.\n",
    "\n",
    "    if os.path.isdir(folder_path):  # Check if the current item is a directory.\n",
    "        # Dynamically construct paths for processing the folder\n",
    "        AUGMENTED_FOLDERS = folder_path  # Set the path of the current folder as the augmented data folder.\n",
    "        RESULT_NAME_TRAIN = f'embed_{folder_name}.csv'  # Dynamically create a CSV file name based on the folder name.\n",
    "\n",
    "        # Debugging: Print paths to verify correctness\n",
    "        print(f\"Processing folder: {AUGMENTED_FOLDERS}\")  # Print the path of the augmented folder being processed.\n",
    "        print(f\"Output folder: {OUTPUT_FOLDER_RESULTS_TEST}\")  # Print the path where the results will be saved.\n",
    "        print(f\"Result file: {RESULT_NAME_TRAIN}\")  # Print the name of the result file.\n",
    "\n",
    "        # Call embedding function to process the augmented data\n",
    "        main_embed.embed(AUGMENTED_FOLDERS, OUTPUT_FOLDER_RESULTS_TEST, RESULT_NAME_TRAIN)\n",
    "        # The embedding function processes images in the augmented folder,\n",
    "        # computes embeddings, and saves the results in the specified output folder as a CSV file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Outcomes and Plots\n",
    "\n",
    "Processed results for different thresholds are saved as `.csv` files in the `test_results` folder. Thresholds like `0.80`, `0.85`, `0.90`, and `0.95` are used to analyze clustering sensitivity. Visual plots are created to show actor presence across clusters, aiding in understanding data patterns and threshold impact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the test_results directory exists\n",
    "os.makedirs(\"test_results\", exist_ok=True)  \n",
    "# This ensures the directory \"test_results\" is created if it does not already exist,\n",
    "# allowing results to be saved without errors.\n",
    "\n",
    "thresholds = [0.80, 0.85, 0.9, 0.95]\n",
    "for threshold in thresholds:\n",
    "    # Calculate the threshold distance for the current percentile\n",
    "    threshold_distance = np.percentile(distances_train, threshold * 100)\n",
    "    \n",
    "    # Process the test embeddings with the current threshold\n",
    "    results_df = cluster_dataframe.process_test_embeddings(\n",
    "        test_embeddings=test_embeddings,\n",
    "        test_embeddings_df=test_embeddings_df,\n",
    "        kmeans=kmeans,\n",
    "        output_folder='recognition-output',\n",
    "        face_folder_test='face_folder_test',\n",
    "        threshold=threshold_distance,\n",
    "        results_output_path = f'test_results\\\\test_results_{threshold}.csv',\n",
    "    )\n",
    "    \n",
    "    # Plot actor presence\n",
    "    plots.plot_actor_presence(results_df, 'Cluster', cluster_choice,f'test_results_{threshold}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Augmented Results\n",
    "\n",
    "Augmented results are saved as `.csv` files in the `distorted_results` directory. Each file in the `OUTPUT_FOLDER_RESULTS_TEST` directory is processed, converting embeddings for clustering using a pre-trained KMeans model and a distance threshold (`threshold_distance_85`). Results are analyzed and plotted to visualize actor presence across clusters, helping assess the robustness of clustering models against augmented data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the distorted_result directory exists\n",
    "os.makedirs(\"distorted_results\", exist_ok=True)  \n",
    "# This ensures the directory \"distorted_result\" is created if it does not already exist,\n",
    "# allowing results to be saved without errors.\n",
    "\n",
    "# Iterate through all files in the OUTPUT_FOLDER_RESULTS_TEST directory\n",
    "for file_name in os.listdir(OUTPUT_FOLDER_RESULTS_TEST):  \n",
    "    file_path = os.path.join(OUTPUT_FOLDER_RESULTS_TEST, file_name)  # Construct the full file path.\n",
    "\n",
    "    # Check if the current file is a CSV file\n",
    "    if file_name.endswith('.csv') and os.path.isfile(file_path):  \n",
    "        print(f\"Processing file: {file_name}\")  # Debugging: Print the name of the file being processed.\n",
    "\n",
    "        # Read the embeddings from the CSV file\n",
    "        test_embeddings_df = pd.read_csv(file_path)  # Load the embeddings into a Pandas DataFrame.\n",
    "        test_embeddings = test_embeddings_df.T.values  # Convert the DataFrame to a NumPy array for processing.\n",
    "        print(test_embeddings_df.columns)  # Debugging: Print the column names of the embeddings.\n",
    "\n",
    "        # Process the embeddings and generate results\n",
    "        results_df = cluster_dataframe.process_test_embeddings(\n",
    "            test_embeddings=test_embeddings,  # Array of test embedding vectors.\n",
    "            test_embeddings_df=test_embeddings_df,  # DataFrame containing metadata of test embeddings.\n",
    "            kmeans=kmeans,  # Pre-trained KMeans model for clustering.\n",
    "            output_folder='recognition-output',  # Directory where clustering results will be saved.\n",
    "            face_folder_test=\"face_folder_test\",  # Directory containing test face images.\n",
    "            threshold=threshold_distance_85,  # Distance threshold for determining cluster assignment.\n",
    "            results_output_path=f\"distorted_results\\\\{file_name}\",  # File path for saving results.\n",
    "        )\n",
    "        # The function processes test embeddings, assigns clusters, and saves results in the specified directory.\n",
    "\n",
    "        # Plot actor presence based on cluster assignment\n",
    "        plots.plot_actor_presence(results_df, 'Cluster', cluster_choice, file_name)  \n",
    "        # Generate a histogram showing actor presence in clusters using the processed results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
